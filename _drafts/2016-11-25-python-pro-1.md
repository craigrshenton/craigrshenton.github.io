---
layout: post
title: "Data Science- 1.2 data pre-processing"
tags:
    - python
    - notebook
---

Data pre-processing in python, using Pima Indians diabetes dataset from National Institute of Diabetes and Digestive and Kidney Diseases

Citation: Lichman, M. (2013). UCI Machine Learning Repository [http://archive.ics.uci.edu/ml]. Irvine, CA: University of California, School of Information and Computer Science.

Feature Information:

1. Number of times pregnant 
2. Plasma glucose concentration a 2 hours in an oral glucose tolerance test 
3. Diastolic blood pressure (mm Hg) 
4. Triceps skin fold thickness (mm) 
5. 2-Hour serum insulin (mu U/ml) 
6. Body mass index (weight in kg/(height in m)^2) 
7. Diabetes pedigree function 
8. Age (years) 
9. Class variable (0 or 1) i.e., Diabetes found? (no/yes)

#### 1.0 Load data from CSV

**In [1]:**

```python
import pandas as pd
from pandas import read_csv
pd.set_option('precision', 3) # set display precision to 3 decimal places

filename = '.../pima-indians-diabetes.data.csv'
names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']
df = read_csv(filename, names=names)
df.head()
```




<div>
<table border="1" class="dataframe">
  <thead>
    <tr>
      <th></th>
      <th>preg</th>
      <th>plas</th>
      <th>pres</th>
      <th>skin</th>
      <th>test</th>
      <th>mass</th>
      <th>pedi</th>
      <th>age</th>
      <th>class</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>6</td>
      <td>148</td>
      <td>72</td>
      <td>35</td>
      <td>0</td>
      <td>33.6</td>
      <td>0.627</td>
      <td>50</td>
      <td>1</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1</td>
      <td>85</td>
      <td>66</td>
      <td>29</td>
      <td>0</td>
      <td>26.6</td>
      <td>0.351</td>
      <td>31</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>8</td>
      <td>183</td>
      <td>64</td>
      <td>0</td>
      <td>0</td>
      <td>23.3</td>
      <td>0.672</td>
      <td>32</td>
      <td>1</td>
    </tr>
    <tr>
      <th>3</th>
      <td>1</td>
      <td>89</td>
      <td>66</td>
      <td>23</td>
      <td>94</td>
      <td>28.1</td>
      <td>0.167</td>
      <td>21</td>
      <td>0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0</td>
      <td>137</td>
      <td>40</td>
      <td>35</td>
      <td>168</td>
      <td>43.1</td>
      <td>2.288</td>
      <td>33</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
</div>



#### 2.0 Split data into feature (input) and target (output) set

**In [2]:**

```python
feature_cols = df.columns[0:8]
X = df[feature_cols]    # first 8 cols are features
y = df['class']            # last col is target data
```

#### 3.0 Rescale

Homogenise data of varying scales to take values between 0 and 1

**In [3]:**

```python
from sklearn.preprocessing import MinMaxScaler

scaler = MinMaxScaler(feature_range=(0, 1))
rescaledX = scaler.fit_transform(X)
df_scaled = pd.DataFrame(data=rescaledX, columns=feature_cols)
df_scaled.head()
```




<div>
<table border="1" class="dataframe">
  <thead>
    <tr>
      <th></th>
      <th>preg</th>
      <th>plas</th>
      <th>pres</th>
      <th>skin</th>
      <th>test</th>
      <th>mass</th>
      <th>pedi</th>
      <th>age</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0.353</td>
      <td>0.744</td>
      <td>0.590</td>
      <td>0.354</td>
      <td>0.000</td>
      <td>0.501</td>
      <td>0.234</td>
      <td>0.483</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.059</td>
      <td>0.427</td>
      <td>0.541</td>
      <td>0.293</td>
      <td>0.000</td>
      <td>0.396</td>
      <td>0.117</td>
      <td>0.167</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.471</td>
      <td>0.920</td>
      <td>0.525</td>
      <td>0.000</td>
      <td>0.000</td>
      <td>0.347</td>
      <td>0.254</td>
      <td>0.183</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.059</td>
      <td>0.447</td>
      <td>0.541</td>
      <td>0.232</td>
      <td>0.111</td>
      <td>0.419</td>
      <td>0.038</td>
      <td>0.000</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.000</td>
      <td>0.688</td>
      <td>0.328</td>
      <td>0.354</td>
      <td>0.199</td>
      <td>0.642</td>
      <td>0.944</td>
      <td>0.200</td>
    </tr>
  </tbody>
</table>
</div>



<!--more-->

#### 4.0 Standardisation

Standardise normally distributed data to have a mean of 0 and standard deviation of 1

**In [4]:**

```python
from sklearn.preprocessing import StandardScaler

scaler = StandardScaler().fit(X)
standardX = scaler.transform(X)
df_standard = pd.DataFrame(data=standardX, columns=feature_cols)
df_standard.head()
```




<div>
<table border="1" class="dataframe">
  <thead>
    <tr>
      <th></th>
      <th>preg</th>
      <th>plas</th>
      <th>pres</th>
      <th>skin</th>
      <th>test</th>
      <th>mass</th>
      <th>pedi</th>
      <th>age</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0.640</td>
      <td>0.848</td>
      <td>0.150</td>
      <td>0.907</td>
      <td>-0.693</td>
      <td>0.204</td>
      <td>0.468</td>
      <td>1.426</td>
    </tr>
    <tr>
      <th>1</th>
      <td>-0.845</td>
      <td>-1.123</td>
      <td>-0.161</td>
      <td>0.531</td>
      <td>-0.693</td>
      <td>-0.684</td>
      <td>-0.365</td>
      <td>-0.191</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1.234</td>
      <td>1.944</td>
      <td>-0.264</td>
      <td>-1.288</td>
      <td>-0.693</td>
      <td>-1.103</td>
      <td>0.604</td>
      <td>-0.106</td>
    </tr>
    <tr>
      <th>3</th>
      <td>-0.845</td>
      <td>-0.998</td>
      <td>-0.161</td>
      <td>0.155</td>
      <td>0.123</td>
      <td>-0.494</td>
      <td>-0.921</td>
      <td>-1.042</td>
    </tr>
    <tr>
      <th>4</th>
      <td>-1.142</td>
      <td>0.504</td>
      <td>-1.505</td>
      <td>0.907</td>
      <td>0.766</td>
      <td>1.410</td>
      <td>5.485</td>
      <td>-0.020</td>
    </tr>
  </tbody>
</table>
</div>



#### 5.0 Normalisation

Normalise data such that each row has a vector length of 1

**In [5]:**

```python
from sklearn.preprocessing import Normalizer

scaler = Normalizer().fit(X)
normalizedX = scaler.transform(X)
df_norm = pd.DataFrame(data=normalizedX, columns=feature_cols)
df_norm.head()
```




<div>
<table border="1" class="dataframe">
  <thead>
    <tr>
      <th></th>
      <th>preg</th>
      <th>plas</th>
      <th>pres</th>
      <th>skin</th>
      <th>test</th>
      <th>mass</th>
      <th>pedi</th>
      <th>age</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0.034</td>
      <td>0.828</td>
      <td>0.403</td>
      <td>0.196</td>
      <td>0.000</td>
      <td>0.188</td>
      <td>0.004</td>
      <td>0.280</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.008</td>
      <td>0.716</td>
      <td>0.556</td>
      <td>0.244</td>
      <td>0.000</td>
      <td>0.224</td>
      <td>0.003</td>
      <td>0.261</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.040</td>
      <td>0.924</td>
      <td>0.323</td>
      <td>0.000</td>
      <td>0.000</td>
      <td>0.118</td>
      <td>0.003</td>
      <td>0.162</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.007</td>
      <td>0.588</td>
      <td>0.436</td>
      <td>0.152</td>
      <td>0.622</td>
      <td>0.186</td>
      <td>0.001</td>
      <td>0.139</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.000</td>
      <td>0.596</td>
      <td>0.174</td>
      <td>0.152</td>
      <td>0.731</td>
      <td>0.188</td>
      <td>0.010</td>
      <td>0.144</td>
    </tr>
  </tbody>
</table>
</div>
