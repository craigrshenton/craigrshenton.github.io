---
layout: post
title: "MS Azure with python- 1.0 feature reduction"
tags:
    - python
    - notebook
---

Following 'Fundamentals of Data Science with Python' course Microsoft's new [Azure Notebooks](https://notebooks.azure.com/) site.

Preprocessing i.e., make the learning easier or better beforehand -  feature reduction/selection/creation
* SelectKBest
* PCA

Selecting k top scoring features (also dimensionality reduction)

**In [1]:**

```python
%matplotlib inline
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
```

**In [2]:**

```python
# SelectKBest for selecting top-scoring features

from sklearn import datasets
from sklearn.feature_selection import SelectKBest, chi2

iris = datasets.load_iris()
X, y = iris.data, iris.target
df = pd.DataFrame(X, columns = iris.feature_names)
print(X.shape)
df.head()
```

    (150, 4)
    

<div>
<table border="1" class="dataframe">
  <thead>
    <tr>
      <th></th>
      <th>sepal length (cm)</th>
      <th>sepal width (cm)</th>
      <th>petal length (cm)</th>
      <th>petal width (cm)</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>5.1</td>
      <td>3.5</td>
      <td>1.4</td>
      <td>0.2</td>
    </tr>
    <tr>
      <th>1</th>
      <td>4.9</td>
      <td>3.0</td>
      <td>1.4</td>
      <td>0.2</td>
    </tr>
    <tr>
      <th>2</th>
      <td>4.7</td>
      <td>3.2</td>
      <td>1.3</td>
      <td>0.2</td>
    </tr>
    <tr>
      <th>3</th>
      <td>4.6</td>
      <td>3.1</td>
      <td>1.5</td>
      <td>0.2</td>
    </tr>
    <tr>
      <th>4</th>
      <td>5.0</td>
      <td>3.6</td>
      <td>1.4</td>
      <td>0.2</td>
    </tr>
  </tbody>
</table>
</div>

<!--more-->

**In [3]:**


```python
# New feature is petal width / sepal width
df['petal width / sepal width'] = df['petal width (cm)'] / df['sepal width (cm)']

# Grab feature names + new one
new_feature_names = df.columns
print('New feature names:', list(new_feature_names))

# We've now added a new column to our data
X = np.array(df)
```

    New feature names: ['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)', 'petal width / sepal width']
    

**In [4]:**

```python
# Perform feature selection

#  Input is scoring function (here chi2) to get univariate p-values
#  and number of top-scoring features (k) - here we get the top 3
dim_red = SelectKBest(chi2, k = 3)

# Train
dim_red.fit(X, y)

# Use model to transform original data
X_t = dim_red.transform(X)
```

**In [5]:**

```python
# Show scores, features selected and new shape
print('Scores:', dim_red.scores_)
print('New shape:', X_t.shape)
```

    Scores: [  10.81782088    3.59449902  116.16984746   67.24482759]
    New shape: (150, 3)
    

**In [6]:**

```python
# Get back the selected columns
selected = dim_red.get_support()
selected_names = new_feature_names[selected]

print('Top k features: ', list(selected_names))
```

    Top k features:  ['petal length (cm)', 'petal width (cm)', 'petal width / sepal width']
    

**Note on scoring function selection in `SelectKBest` tranformations:**
* For regression - [f_regression](http://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.f_regression.html#sklearn.feature_selection.f_regression)
* For classification - [chi2](http://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.chi2.html#sklearn.feature_selection.chi2), [f_classif](http://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.f_classif.html#sklearn.feature_selection.f_classif)

